# 3.4 从LLM到智能体架构

上一节我们看到了大语言模型的四大局限：知识截断、幻觉、计算弱、不会执行。这些局限看似棘手，但解决思路其实很清晰——**用架构来弥补模型的不足**。

这就是智能体存在的意义：让模型专注于它擅长的"理解和推理"，把它不擅长的事情交给专门的工具和机制来处理。

---

## 3.4.1 智能体如何弥补LLM的不足

每一个局限都有对应的解决方案：

| 大语言模型局限 | 表现形式 | 智能体增强方案 | 关键技术 | 参考章节 |
|--------------|---------|---------------|---------|----------|
| 知识截断 | 不知道训练后的新信息 | 实时信息检索 | RAG | 第8章 |
| 幻觉问题 | 编造虚假但看似合理的信息 | 工具验证+反思 | Tool Calling, Reflection | 第4章 |
| 计算能力不足 | 数学计算频繁出错 | 专用工具调用 | Function Calling | 第4章 |
| 缺乏执行能力 | 只能生成文本,不能操作 | 执行器集成 | Tool Execution | 第4章 |

### 智能体的四层架构

把这些解决方案组合起来，就形成了智能体的四层架构：

```
用户输入:"帮我查询北京天气,如果是晴天就预订明天的故宫门票"
    ↓
┌──────────────────────────────────────────┐
│  推理层:大语言模型(LLM)                    │
│  - 理解复杂意图:天气查询+条件判断+预订       │
│  - 任务分解:先查天气 → 判断条件 → 执行预订  │
│  - 生成执行计划                            │
└──────────────────────────────────────────┘
    ↓
┌──────────────────────────────────────────┐
│  工具层:外部工具集成                        │
│  - weather_api: 查询实时天气 ✓             │
│  - booking_api: 预订景区门票 ✓             │
│  - calculator: 费用计算 ✓                  │
└──────────────────────────────────────────┘
    ↓
┌──────────────────────────────────────────┐
│  记忆层:上下文管理                          │
│  - 短期记忆:当前会话的对话历史              │
│  - 长期记忆:用户历史偏好、订单记录           │
└──────────────────────────────────────────┘
    ↓
┌──────────────────────────────────────────┐
│  反思层:质量保证                            │
│  - 信息验证:天气数据是否为最新?             │
│  - 执行检查:预订操作是否成功?               │
│  - 错误修正:失败时尝试备选方案              │
└──────────────────────────────────────────┘
    ↓
输出:"北京明天天气晴朗,已为您预订故宫门票(成人票×1),订单号:20251217001"
```

### 四个增强维度详解

#### 维度一：知识时效性增强(RAG)

模型不知道新信息？让它先"查资料"再回答：

```python
# 步骤1: 使用搜索工具检索实时信息
search_result = search_tool("2024巴黎奥运会金牌榜")

# 步骤2: 将检索结果作为上下文注入提示词
prompt = f"""
根据以下最新信息回答问题:

检索结果:
{search_result}

问题:2024年巴黎奥运会金牌榜前三名分别是哪些国家?
"""

# 步骤3: 大语言模型基于最新信息生成答案
answer = llm.generate(prompt)  # ✓ 获得准确的最新答案
```

#### 维度二：信息可靠性增强(工具验证)

模型会编造信息？让它用工具查真实数据，而不是"凭空想象"：

```python
class TravelAgent:
    def recommend_cafe(self, city, keyword):
        # 步骤1: 识别需要外部信息
        thought = "用户需要咖啡馆推荐,应使用搜索工具获取真实信息,而非基于推测"

        # 步骤2: 调用搜索工具获取真实数据
        results = self.search_tool(f"{city} {keyword} 咖啡馆")

        # 步骤3: 基于真实搜索结果生成回答
        if not results:
            return "抱歉,未找到符合条件的咖啡馆信息。"
        else:
            return self.llm.generate(
                f"根据以下搜索结果进行推荐:\n{results}"
            )  # ✓ 基于真实数据,减少幻觉风险
```

#### 维度三：计算准确性增强(专用工具)

模型算术不行？让它调用计算器：

```python
class MathAgent:
    def solve(self, expression):
        # 步骤1: 判断是否为计算任务
        if self._is_calculation(expression):
            # 步骤2: 调用计算器工具获得精确结果
            result = self.calculator_tool.eval(expression)  # ✓ 精确计算
            return f"{expression} = {result}"

        # 步骤3: 对于数学推理题,交由大语言模型处理
        elif self._is_math_reasoning(expression):
            return self.llm.solve_reasoning(expression)

        else:
            return "无法识别的数学问题类型"
```

#### 维度四：实际执行力增强(执行器)

模型只会说不会做？让它生成内容，让工具去执行：

```python
class EmailAgent:
    def send_email(self, recipient, subject, key_points):
        # 步骤1: 使用大语言模型生成邮件内容
        content = self.llm.generate(
            f"撰写一封给{recipient}的{subject}邮件,要点包括:{key_points}"
        )

        # 步骤2: 调用邮件API真正发送邮件
        send_result = self.email_api.send(
            to=recipient,
            subject=subject,
            body=content,
            cc=self.config.get('default_cc')
        )  # ✓ 邮件真正被发送

        # 步骤3: 返回执行状态
        if send_result.success:
            return f"邮件已成功发送至{recipient},消息ID:{send_result.message_id}"
        else:
            return f"邮件发送失败:{send_result.error_message}"
```

---

## 3.4.2 如何选择大语言模型

不同场景需要不同模型，合理选择可以在性能和成本之间取得平衡。

### 主流模型一览

| 模型名称 | 参数规模 | 核心优势 | 典型应用场景 | 相对成本 |
|---------|---------|---------|-------------|---------|
| GPT-5 | ~1.7T | 推理与生成能力平衡 | 复杂智能体任务 | 高 |
| Claude 3.5 Sonnet | 未公开 | 超长上下文(200K) | 文档分析、法律咨询 | 中高 |
| Gemini Pro | 未公开 | 多模态能力强 | 图文混合任务 | 中 |
| Llama 3 | 70B | 开源可本地部署 | 隐私敏感场景 | 低(自部署) |
| Qwen | 72B | 中文理解能力优 | 中文智能体 | 低 |

注:参数规模中T=万亿(Trillion),B=十亿(Billion)

### 怎么选？看这棵决策树

```
                    任务是否涉及多模态(图像/视频/音频)?
                    /                              \
                是/                                否\
                 ↓                                  ↓
         Gemini Pro                         主要处理中文内容?
         GPT-4V                              /              \
                                         是/                否\
                                          ↓                  ↓
                                      Qwen/GLM        是否需要超长上下文?
                                                      /              \
                                                  是/                否\
                                                   ↓                  ↓
                                             Claude 3.5        是否需要最强推理?
                                                               /              \
                                                           是/                否\
                                                            ↓                  ↓
                                                         GPT-5        Llama 3(开源)
                                                                     Qwen(本地部署)
```

### 成本优化的两个技巧

#### 技巧一：分级调用

简单问题用便宜模型，复杂问题才用贵的：

```python
class SmartAgent:
    def __init__(self):
        self.fast_model = "gpt-4o-mini"   # 快速廉价模型
        self.strong_model = "gpt-5"        # 强大昂贵模型

    def think(self, task):
        # 简单任务使用小模型
        if self._is_simple_task(task):
            return self.call_llm(self.fast_model, task)
        # 复杂任务使用大模型
        else:
            return self.call_llm(self.strong_model, task)

    def _is_simple_task(self, task):
        """判断任务复杂度"""
        # 简单任务特征:输入短、无需复杂推理
        return (len(task) < 100 and
                not self._requires_multi_step_reasoning(task))
```

#### 技巧二：响应缓存

相同的问题不要重复调用，用缓存省钱：

```python
import hashlib
import json

class CachedAgent:
    def __init__(self):
        self.cache = {}  # 简单内存缓存,生产环境应使用Redis等
        self.cache_ttl = 3600  # 缓存有效期(秒)

    def think(self, prompt):
        # 计算提示词的哈希值作为缓存键
        cache_key = hashlib.md5(
            json.dumps(prompt, sort_keys=True).encode()
        ).hexdigest()

        # 检查缓存
        if cache_key in self.cache:
            cached_response, timestamp = self.cache[cache_key]
            if time.time() - timestamp < self.cache_ttl:
                return cached_response  # 命中缓存,无需调用API

        # 缓存未命中,调用大语言模型
        response = self.llm.generate(prompt)

        # 存入缓存
        self.cache[cache_key] = (response, time.time())
        return response
```

---

## 3.4.3 大语言模型的发展趋势

了解模型的发展方向，可以帮助我们设计更有前瞻性的智能体架构。

### 趋势一：推理增强模型

OpenAI的o1系列模型开创了新范式：模型在给出答案前先进行"内部推理"[1]。

```python
# 传统模型
Q: "这道数学应用题怎么解?"
A: [直接生成答案] (容易出错)

# 推理增强模型
Q: "这道数学应用题怎么解?"
A: [内部执行多步推理] → [自我验证] → [输出经过验证的解法]
```

这对智能体意味着：幻觉会减少（模型会自我验证），规划能力会增强，但调用成本也会上升（内部推理消耗更多token）。

### 趋势二：原生工具调用能力

新一代模型将工具调用作为原生能力，无需复杂的提示词工程：

```python
# 传统方式:需要在System Prompt中详细描述工具格式
system_prompt = """
可用工具:
- calculator(expression: str): 计算数学表达式
- search(query: str): 搜索网络信息
输出格式:{"tool": "工具名", "parameters": {...}}
"""

# 新方式:直接传入工具定义,模型原生理解
tools = [
    {
        "type": "function",
        "function": {
            "name": "calculator",
            "description": "执行数学表达式计算",
            "parameters": {
                "type": "object",
                "properties": {
                    "expression": {
                        "type": "string",
                        "description": "要计算的数学表达式"
                    }
                },
                "required": ["expression"]
            }
        }
    }
]

response = llm.chat(messages, tools=tools)
# 模型直接输出结构化的tool_calls,无需额外解析
```

### 趋势三：多模态智能体

未来的智能体不仅能处理文本，还能理解图像、视频、音频：

```python
# 多模态智能体示例
agent.run([
    {"type": "text", "content": "分析这个网页的用户体验设计"},
    {"type": "image", "content": screenshot_data},
    {"type": "text", "content": "生成改进建议和修改方案"}
])

# 输出:文字分析报告 + 标注图片 + 代码修改建议
```

---

## 本节小结

智能体架构的本质是**用架构弥补模型的不足**：

| 模型局限 | 智能体方案 | 核心技术 |
|---------|---------|---------|
| 知识截断 | 实时检索 | RAG |
| 幻觉 | 工具验证 | Tool Calling |
| 计算弱 | 专用工具 | Function Calling |
| 不会执行 | 执行器 | Tool Execution |

模型选择方面，根据任务特征（多模态、语言、上下文长度、推理复杂度）选择合适的模型，并通过分级调用和响应缓存降低成本。

大语言模型是智能体的"大脑"，但只有通过架构赋予它"工具"、"记忆"和"反思"机制，才能构建真正可靠的智能系统。

在下一章中，我们将开始动手实践，构建第一个完整的智能体系统。

---

## 参考文献

[1] OpenAI. OpenAI o1 System Card[R]. OpenAI Technical Report, 2024.

---

[⬅️ 上一节:LLM的能力与边界](3.3-LLM的能力与边界.md) | [🏠 返回目录](README.md) | [➡️ 下一章:智能体经典范式构建](../chapter04/README.md)
