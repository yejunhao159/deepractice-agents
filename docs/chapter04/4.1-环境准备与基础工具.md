# 4.1 ç¯å¢ƒå‡†å¤‡ä¸åŸºç¡€å·¥å…·

åœ¨å¼€å§‹æ„å»ºæ™ºèƒ½ä½“ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦æ­å»ºå¼€å‘ç¯å¢ƒå¹¶å®šä¹‰ä¸€äº›åŸºç¡€ç»„ä»¶ã€‚è¿™äº›å‡†å¤‡å·¥ä½œå°†åœ¨åç»­å®ç°ä¸åŒèŒƒå¼æ—¶è¢«å¤ç”¨ã€‚

---

## 4.1.1 å®‰è£…ä¾èµ–

æœ¬ç« ä½¿ç”¨ Python è¯­è¨€ï¼Œå»ºè®®ä½¿ç”¨ Python 3.10 æˆ–æ›´é«˜ç‰ˆæœ¬ã€‚

```bash
pip install openai python-dotenv
```

- `openai`ï¼šç”¨äºè°ƒç”¨å¤§è¯­è¨€æ¨¡å‹ API
- `python-dotenv`ï¼šç”¨äºç®¡ç†ç¯å¢ƒå˜é‡

---

## 4.1.2 é…ç½® API å¯†é’¥

åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º `.env` æ–‡ä»¶ï¼Œé…ç½®æ¨¡å‹æœåŠ¡ä¿¡æ¯ï¼š

```bash
# .env file
LLM_API_KEY="YOUR-API-KEY"
LLM_MODEL_ID="YOUR-MODEL"
LLM_BASE_URL="YOUR-URL"
```

è¿™ç§é…ç½®æ–¹å¼çš„å¥½å¤„æ˜¯ï¼š
1. æ•æ„Ÿä¿¡æ¯ä¸ä¼šç¡¬ç¼–ç åœ¨ä»£ç ä¸­
2. å¯ä»¥æ–¹ä¾¿åœ°åˆ‡æ¢ä¸åŒçš„æ¨¡å‹æœåŠ¡
3. æ”¯æŒ OpenAI å®˜æ–¹æœåŠ¡æˆ–ä»»ä½•å…¼å®¹æ¥å£çš„ç¬¬ä¸‰æ–¹æœåŠ¡

> å¦‚æœä¸ç¡®å®šå¦‚ä½•è·å– API å¯†é’¥ï¼Œå¯å‚è€ƒ [Datawhale APIè®¾ç½®æ•™ç¨‹](https://datawhalechina.github.io/handy-multi-agent/#/chapter1/1.2.api-setup)

---

## 4.1.3 å°è£… LLM å®¢æˆ·ç«¯

ä¸ºäº†è®©ä»£ç æ›´æ¸…æ™°ã€æ›´æ˜“å¤ç”¨ï¼Œæˆ‘ä»¬å°è£…ä¸€ä¸ªä¸“ç”¨çš„ LLM å®¢æˆ·ç«¯ç±»ï¼š

```python
import os
from openai import OpenAI
from dotenv import load_dotenv
from typing import List, Dict

# åŠ è½½ .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
load_dotenv()

class HelloAgentsLLM:
    """
    ä¸ºæœ¬ä¹¦å®šåˆ¶çš„LLMå®¢æˆ·ç«¯ã€‚
    æ”¯æŒä»»ä½•å…¼å®¹OpenAIæ¥å£çš„æœåŠ¡ï¼Œé»˜è®¤ä½¿ç”¨æµå¼å“åº”ã€‚
    """
    def __init__(self, model: str = None, apiKey: str = None, baseUrl: str = None, timeout: int = None):
        """
        åˆå§‹åŒ–å®¢æˆ·ç«¯ã€‚ä¼˜å…ˆä½¿ç”¨ä¼ å…¥å‚æ•°ï¼Œå¦åˆ™ä»ç¯å¢ƒå˜é‡åŠ è½½ã€‚
        """
        self.model = model or os.getenv("LLM_MODEL_ID")
        apiKey = apiKey or os.getenv("LLM_API_KEY")
        baseUrl = baseUrl or os.getenv("LLM_BASE_URL")
        timeout = timeout or int(os.getenv("LLM_TIMEOUT", 60))

        if not all([self.model, apiKey, baseUrl]):
            raise ValueError("æ¨¡å‹IDã€APIå¯†é’¥å’ŒæœåŠ¡åœ°å€å¿…é¡»æä¾›æˆ–åœ¨.envæ–‡ä»¶ä¸­å®šä¹‰ã€‚")

        self.client = OpenAI(api_key=apiKey, base_url=baseUrl, timeout=timeout)

    def think(self, messages: List[Dict[str, str]], temperature: float = 0) -> str:
        """
        è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œæ€è€ƒï¼Œè¿”å›å“åº”æ–‡æœ¬ã€‚

        å‚æ•°:
        - messages: æ¶ˆæ¯åˆ—è¡¨ï¼Œæ ¼å¼ä¸º [{"role": "user", "content": "..."}]
        - temperature: æ¸©åº¦å‚æ•°ï¼Œ0è¡¨ç¤ºç¡®å®šæ€§è¾“å‡º

        è¿”å›:
        - æ¨¡å‹å“åº”çš„å®Œæ•´æ–‡æœ¬
        """
        print(f"ğŸ§  æ­£åœ¨è°ƒç”¨ {self.model} æ¨¡å‹...")
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=temperature,
                stream=True,
            )

            # å¤„ç†æµå¼å“åº”
            print("âœ… å¤§è¯­è¨€æ¨¡å‹å“åº”æˆåŠŸ:")
            collected_content = []
            for chunk in response:
                content = chunk.choices[0].delta.content or ""
                print(content, end="", flush=True)
                collected_content.append(content)
            print()  # æ¢è¡Œ
            return "".join(collected_content)

        except Exception as e:
            print(f"âŒ è°ƒç”¨LLM APIæ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return None
```

**ä½¿ç”¨ç¤ºä¾‹ï¼š**

```python
if __name__ == '__main__':
    llmClient = HelloAgentsLLM()

    messages = [
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "å†™ä¸€ä¸ªå¿«é€Ÿæ’åºç®—æ³•"}
    ]

    response = llmClient.think(messages)
```

---

## 4.1.4 å®šä¹‰å·¥å…·æ‰§è¡Œå™¨

æ™ºèƒ½ä½“éœ€è¦è°ƒç”¨å¤–éƒ¨å·¥å…·æ¥å®Œæˆä»»åŠ¡ã€‚æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªé€šç”¨çš„å·¥å…·ç®¡ç†å™¨ï¼š

```python
from typing import Dict, Any

class ToolExecutor:
    """
    å·¥å…·æ‰§è¡Œå™¨ï¼Œè´Ÿè´£ç®¡ç†å’Œæ‰§è¡Œå·¥å…·ã€‚
    """
    def __init__(self):
        self.tools: Dict[str, Dict[str, Any]] = {}

    def registerTool(self, name: str, description: str, func: callable):
        """
        æ³¨å†Œä¸€ä¸ªæ–°å·¥å…·ã€‚

        å‚æ•°:
        - name: å·¥å…·åç§°ï¼Œä¾›æ™ºèƒ½ä½“è°ƒç”¨
        - description: å·¥å…·æè¿°ï¼Œå¸®åŠ©æ™ºèƒ½ä½“åˆ¤æ–­ä½•æ—¶ä½¿ç”¨
        - func: å·¥å…·çš„æ‰§è¡Œå‡½æ•°
        """
        if name in self.tools:
            print(f"è­¦å‘Š: å·¥å…· '{name}' å·²å­˜åœ¨ï¼Œå°†è¢«è¦†ç›–ã€‚")
        self.tools[name] = {"description": description, "func": func}
        print(f"å·¥å…· '{name}' å·²æ³¨å†Œã€‚")

    def getTool(self, name: str) -> callable:
        """æ ¹æ®åç§°è·å–å·¥å…·çš„æ‰§è¡Œå‡½æ•°ã€‚"""
        return self.tools.get(name, {}).get("func")

    def getAvailableTools(self) -> str:
        """è·å–æ‰€æœ‰å¯ç”¨å·¥å…·çš„æ ¼å¼åŒ–æè¿°ã€‚"""
        return "\n".join([
            f"- {name}: {info['description']}"
            for name, info in self.tools.items()
        ])
```

ä¸€ä¸ªè‰¯å¥½å®šä¹‰çš„å·¥å…·éœ€è¦åŒ…å«ä¸‰ä¸ªè¦ç´ ï¼š

| è¦ç´  | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|
| **åç§°** | ç®€æ´çš„å”¯ä¸€æ ‡è¯†ç¬¦ | `Search` |
| **æè¿°** | è¯´æ˜å·¥å…·ç”¨é€”ï¼Œä¾›æ¨¡å‹åˆ¤æ–­ | "æœç´¢ç½‘ç»œä¿¡æ¯" |
| **æ‰§è¡Œå‡½æ•°** | å®é™…æ‰§è¡Œä»»åŠ¡çš„ä»£ç  | `search(query)` |

å…¶ä¸­ï¼Œ**æè¿°æ˜¯æœ€å…³é”®çš„éƒ¨åˆ†**â€”â€”å¤§è¯­è¨€æ¨¡å‹ä¾èµ–è¿™æ®µæè¿°æ¥åˆ¤æ–­ä½•æ—¶ä½¿ç”¨å“ªä¸ªå·¥å…·ã€‚

---

## 4.1.5 å®ç°æœç´¢å·¥å…·

ä½œä¸ºç¤ºä¾‹ï¼Œæˆ‘ä»¬å®ç°ä¸€ä¸ªåŸºäº SerpApi çš„ç½‘é¡µæœç´¢å·¥å…·ï¼š

```bash
pip install google-search-results
```

åœ¨ `.env` ä¸­æ·»åŠ  API å¯†é’¥ï¼š

```bash
SERPAPI_API_KEY="YOUR_SERPAPI_API_KEY"
```

å·¥å…·å®ç°ï¼š

```python
from serpapi import SerpApiClient

def search(query: str) -> str:
    """
    ç½‘é¡µæœç´¢å·¥å…·ã€‚
    æ™ºèƒ½è§£ææœç´¢ç»“æœï¼Œä¼˜å…ˆè¿”å›ç›´æ¥ç­”æ¡ˆæˆ–çŸ¥è¯†å›¾è°±ä¿¡æ¯ã€‚
    """
    print(f"ğŸ” æ­£åœ¨æœç´¢: {query}")
    try:
        api_key = os.getenv("SERPAPI_API_KEY")
        if not api_key:
            return "é”™è¯¯: SERPAPI_API_KEY æœªé…ç½®ã€‚"

        params = {
            "engine": "google",
            "q": query,
            "api_key": api_key,
            "gl": "cn",
            "hl": "zh-cn",
        }

        client = SerpApiClient(params)
        results = client.get_dict()

        # æ™ºèƒ½è§£æï¼šä¼˜å…ˆè¿”å›ç›´æ¥ç­”æ¡ˆ
        if "answer_box" in results and "answer" in results["answer_box"]:
            return results["answer_box"]["answer"]
        if "knowledge_graph" in results and "description" in results["knowledge_graph"]:
            return results["knowledge_graph"]["description"]
        if "organic_results" in results and results["organic_results"]:
            # è¿”å›å‰ä¸‰ä¸ªæœç´¢ç»“æœçš„æ‘˜è¦
            snippets = [
                f"[{i+1}] {res.get('title', '')}\n{res.get('snippet', '')}"
                for i, res in enumerate(results["organic_results"][:3])
            ]
            return "\n\n".join(snippets)

        return f"æœªæ‰¾åˆ°å…³äº '{query}' çš„ä¿¡æ¯ã€‚"

    except Exception as e:
        return f"æœç´¢é”™è¯¯: {e}"
```

---

## 4.1.6 æµ‹è¯•åŸºç¡€ç»„ä»¶

å°†æœç´¢å·¥å…·æ³¨å†Œåˆ°æ‰§è¡Œå™¨ï¼Œå¹¶è¿›è¡Œæµ‹è¯•ï¼š

```python
if __name__ == '__main__':
    # 1. åˆå§‹åŒ–å·¥å…·æ‰§è¡Œå™¨
    toolExecutor = ToolExecutor()

    # 2. æ³¨å†Œæœç´¢å·¥å…·
    toolExecutor.registerTool(
        "Search",
        "ç½‘é¡µæœç´¢å¼•æ“ã€‚ç”¨äºæŸ¥è¯¢æ—¶äº‹ã€äº‹å®ç­‰çŸ¥è¯†åº“ä¹‹å¤–çš„ä¿¡æ¯ã€‚",
        search
    )

    # 3. æŸ¥çœ‹å¯ç”¨å·¥å…·
    print("\n--- å¯ç”¨å·¥å…· ---")
    print(toolExecutor.getAvailableTools())

    # 4. æµ‹è¯•å·¥å…·è°ƒç”¨
    print("\n--- æµ‹è¯•æœç´¢ ---")
    tool = toolExecutor.getTool("Search")
    result = tool("è‹±ä¼Ÿè¾¾æœ€æ–°çš„GPUå‹å·")
    print(result)
```

**è¾“å‡ºç¤ºä¾‹ï¼š**

```
å·¥å…· 'Search' å·²æ³¨å†Œã€‚

--- å¯ç”¨å·¥å…· ---
- Search: ç½‘é¡µæœç´¢å¼•æ“ã€‚ç”¨äºæŸ¥è¯¢æ—¶äº‹ã€äº‹å®ç­‰çŸ¥è¯†åº“ä¹‹å¤–çš„ä¿¡æ¯ã€‚

--- æµ‹è¯•æœç´¢ ---
ğŸ” æ­£åœ¨æœç´¢: è‹±ä¼Ÿè¾¾æœ€æ–°çš„GPUå‹å·
[1] GeForce RTX 50 ç³»åˆ—æ˜¾å¡
GeForce RTXâ„¢ 50 ç³»åˆ—GPU æ­è½½NVIDIA Blackwell æ¶æ„...
```

è‡³æ­¤ï¼Œæˆ‘ä»¬å·²ç»å‡†å¤‡å¥½äº†æ„å»ºæ™ºèƒ½ä½“æ‰€éœ€çš„å…¨éƒ¨åŸºç¡€ç»„ä»¶ï¼š
- LLM å®¢æˆ·ç«¯ï¼šè´Ÿè´£ä¸å¤§è¯­è¨€æ¨¡å‹äº¤äº’
- å·¥å…·æ‰§è¡Œå™¨ï¼šè´Ÿè´£ç®¡ç†å’Œè°ƒç”¨å¤–éƒ¨å·¥å…·
- æœç´¢å·¥å…·ï¼šæ™ºèƒ½ä½“è¿æ¥äº’è”ç½‘çš„èƒ½åŠ›

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†åŸºäºè¿™äº›ç»„ä»¶ï¼Œå®ç°ç¬¬ä¸€ä¸ªæ™ºèƒ½ä½“èŒƒå¼â€”â€”ReActã€‚

---

[â¬…ï¸ è¿”å›ç›®å½•](README.md) | [â¡ï¸ ä¸‹ä¸€èŠ‚ï¼šReActèŒƒå¼](4.2-ReActèŒƒå¼.md)
